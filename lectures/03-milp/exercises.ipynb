{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to install dependencies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ligo.skymap 'scipy<1.14.0' 'numpy<2' highspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Optimization: Linear and Integer Linear Programming\n",
    "\n",
    "## Linear programming: standard form\n",
    "\n",
    "Linear programming is a mathematical optimization technique that is useful for modeling and solving problems related to allocation of limited resources. A linear program is a system of linear equations and inequalities. Any linear program (LP) can be written in the following canonical form:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textnormal{Find the vector } & \\mathbf{x} \\\\\n",
    "\\textnormal{that minimizes } & \\mathbf{c}^\\mathsf{T}\\mathbf{x} \\\\\n",
    "\\textnormal{subject to the constraints } & \\mathbf{A} \\mathbf{x} \\leq \\mathbf{b} \\\\\n",
    "\\textnormal{and } & \\mathbf{x} \\geq \\mathbf{0}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "(Note that usually this definition calls for maximization, not minimization, but Scipy's linear programming functions perform minimization.)\n",
    "\n",
    "## Linear programming example\n",
    "\n",
    "Prof. Muffinman and Dr. Lemonade need to purchase snacks for day 3 of their summer school. There are 30 students. Each student will write 20 lines of code per cup of tea they drink, 100 per cup of coffee, 100 per muffin, 20 per donut (because the donuts give them tummy aches), and 70 per bagel. Here are the unit prices for the treats:\n",
    "\n",
    "| Item   | Cost  |\n",
    "| ------ | ----- |\n",
    "| Tea    | $1.00 |\n",
    "| Coffee | $2.00 |\n",
    "| Muffin | $2.00 |\n",
    "| Donut  | $3.50 |\n",
    "| Bagel  | $2.00 |\n",
    "\n",
    "Each student must have at least one drink and at least one pastry, at least one of which must be a donut. The Muffinman-Lemonade lab has a budget of $180 for snacks. How many of each snack should they buy? How many lines of code do the students write?\n",
    "\n",
    "**Exercise 1.** Write down a linear cost function and a system of inequalities to model this problem.\n",
    "\n",
    "**Excercise 2.** Express this problem as LP in canonical form by writing down the values of the array $\\mathbf{A}$, the vector $\\mathbf{b}$, and the vector $\\mathbf{c}$.\n",
    "\n",
    "**Exercise 3.** Solve the LP problem using [`scipy.optimize.linprog`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html) by completing the code below. How many of each treat should Muffinman and Lemonade order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "# Fill in these values\n",
    "c = ...\n",
    "A = ...\n",
    "b = ...\n",
    "\n",
    "solution = optimize.linprog(c, A, b)\n",
    "\n",
    "print(f'{-solution.fun:5g} lines of code')\n",
    "varnames = ['teas', 'coffees', 'muffins', 'donuts', 'bagels']\n",
    "for count, name in zip(solution.x, varnames):\n",
    "    print(f'{count:5g} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer linear programming (ILP), mixed integer linear programming (MILP)\n",
    "\n",
    "Integer linear programming (ILP) is an extension of LP in which all of the decision variables $\\mathbf{x}$ are integers. In mixed integer linear programming (MILP), certain of the decision variables are reals and certain are integers.\n",
    "\n",
    "**Exercise 4.** The caterer only sells _whole_ cups of coffee and tea and _whole_ pastries. Solve the LP problem using [`scipy.optimize.milp`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.milp.html) by completing the code below. How many of each treat should Muffinman and Lemonade order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = optimize.milp(\n",
    "    c,\n",
    "    integrality=np.ones_like(1),  # all variables must be integers\n",
    "    constraints=optimize.LinearConstraint(A, ub=b)\n",
    ")\n",
    "\n",
    "print(f'{-solution.fun:5g} lines of code')\n",
    "varnames = ['teas', 'coffees', 'muffins', 'donuts', 'bagels']\n",
    "for count, name in zip(solution.x, varnames):\n",
    "    print(f'{count:5g} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.** There is a sale on bagels: they are half price when you buy them by the dozen. How do you incorporate this into your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "# Fill in these values\n",
    "c = ...\n",
    "A = ...\n",
    "b = ...\n",
    "\n",
    "solution = optimize.milp(\n",
    "    c,\n",
    "    integrality=np.ones_like(c),\n",
    "    constraints=optimize.LinearConstraint(A, ub=b)\n",
    ")\n",
    "\n",
    "print(f'{-solution.fun:5g} lines of code')\n",
    "varnames = ['teas', 'coffees', 'muffins', 'donuts', 'bagels']\n",
    "for count, name in zip(solution.x, varnames):\n",
    "    print(f'{count:5g} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.** Model and solve the problem using the [high-level Python interface to the HiGHS solver](https://ergo-code.github.io/HiGHS/dev/interfaces/python/).\n",
    "\n",
    "This is the same solver that SciPy uses, but it provides a higher-level interface that allows you to input the model symbollically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import highspy\n",
    "\n",
    "model = highspy.Highs()\n",
    "\n",
    "# Create decision variables\n",
    "teas = model.addIntegral()\n",
    "coffees = model.addIntegral()\n",
    "# fill me in...\n",
    "muffins = model.addIntegral()\n",
    "donuts = model.addIntegral()\n",
    "bagels = model.addIntegral()\n",
    "bagel_dozens = model.addIntegral()\n",
    "bagel_singles = model.addIntegral()\n",
    "\n",
    "# Add constraints\n",
    "model.addConstr(teas + coffees >= 30)\n",
    "# fill me in...\n",
    "\n",
    "# Fill me in\n",
    "model.maximize(20 * teas + ...)\n",
    "\n",
    "print(f'{model.getObjectiveValue():5g} lines of code')\n",
    "varnames = ['teas', 'coffees', 'muffins', 'donuts', 'bagels']\n",
    "for count, name in zip(model.allVariableValues(), varnames):\n",
    "    print(f'{count:5g} {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MILP for astronomical observation planning\n",
    "\n",
    "Let's use MILP to plan follow-up of a LIGO-Virgo event. We'll use [S230529ay](https://gracedb.ligo.org/superevents/S230529ay/), a NSBH merger candidate that ZTF actually followed up ([GCN Circular 33900](https://gcn.nasa.gov/circulars/33900)). We'll download all of the data for you below, so all you have to do is the math! ðŸ˜‰\n",
    "\n",
    "### Problem setup\n",
    "\n",
    "We'll use the following Python packages to help us set up the problem:\n",
    "\n",
    "- [ligo.skymap](https://pypi.org/project/ligo.skymap/) for reading and plotting LIGO-Virgo HEALPix localization maps\n",
    "- [astropy-healpix](https://pypi.org/project/astropy-healpix/) for converting HEALPix coordinates to RA and Dec\n",
    "- [healpy](https://pypi.org/project/healpy/) for finding the HEALPix pixels contained within polygon regions\n",
    "- [astroplan](https://pypi.org/project/astroplan/) for finding when a given ZTF field is observable\n",
    "\n",
    "(Note from this point on that these examples work on Linux and macOS but _not_ Windows.)\n",
    "\n",
    "First, some imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "\n",
    "import astroplan\n",
    "from astropy.coordinates import ICRS, SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.table import QTable\n",
    "from astropy.time import Time\n",
    "from astropy_healpix import HEALPix\n",
    "from ligo.skymap import plot\n",
    "from ligo.skymap.io import read_sky_map\n",
    "import healpy as hp\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.simplefilter('ignore', astroplan.TargetNeverUpWarning)\n",
    "warnings.simplefilter('ignore', astroplan.TargetAlwaysUpWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read localization map\n",
    "\n",
    "First, we'll download and plot the sky map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap, metadata = read_sky_map('https://gracedb.ligo.org/api/superevents/S231113bw/files/bayestar.multiorder.fits')\n",
    "\n",
    "ax = plt.axes(projection='astro mollweide')\n",
    "ax.imshow_hpx(skymap, cmap='cylon')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the event time from the sky map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_time = Time(metadata['gps_time'], format='gps').utc\n",
    "event_time.format = 'iso'\n",
    "event_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ZTF focal plane footprint\n",
    "\n",
    "Let's create a model of the footprint of the ZTF focal plane, with the telescope pointed at a reference position of R.A.=0Â°, Dec.=0Â°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 from Bellm et al. (2019)\n",
    "# http://adsabs.harvard.edu/abs/2019PASP..131a8002B\n",
    "ns_nchips = 4\n",
    "ew_nchips = 4\n",
    "ns_npix = 6144\n",
    "ew_npix = 6160\n",
    "plate_scale = 1.01 * u.arcsec\n",
    "ns_chip_gap = 0.205 * u.deg\n",
    "ew_chip_gap = 0.140 * u.deg\n",
    "\n",
    "ns_total = ns_nchips * ns_npix * plate_scale + (ns_nchips - 1) * ns_chip_gap\n",
    "ew_total = ew_nchips * ew_npix * plate_scale + (ew_nchips - 1) * ew_chip_gap\n",
    "\n",
    "rcid = np.arange(64)\n",
    "\n",
    "chipid, rc_in_chip_id = np.divmod(rcid, 4)\n",
    "ns_chip_index, ew_chip_index = np.divmod(chipid, ew_nchips)\n",
    "ns_rc_in_chip_index = np.where(rc_in_chip_id <= 1, 1, 0)\n",
    "ew_rc_in_chip_index = np.where((rc_in_chip_id == 0) | (rc_in_chip_id == 3), 0, 1)\n",
    "\n",
    "ew_offsets = ew_chip_gap * (ew_chip_index - (ew_nchips - 1) / 2) + ew_npix * plate_scale * (ew_chip_index - ew_nchips / 2) + 0.5 * ew_rc_in_chip_index * plate_scale * ew_npix\n",
    "ns_offsets = ns_chip_gap * (ns_chip_index - (ns_nchips - 1) / 2) + ns_npix * plate_scale * (ns_chip_index - ns_nchips / 2) + 0.5 * ns_rc_in_chip_index * plate_scale * ns_npix\n",
    "\n",
    "ew_ccd_corners = 0.5 * plate_scale * np.asarray([ew_npix, 0, 0, ew_npix])\n",
    "ns_ccd_corners = 0.5 * plate_scale * np.asarray([ns_npix, ns_npix, 0, 0])\n",
    "\n",
    "ew_vertices = ew_offsets[:, np.newaxis] + ew_ccd_corners[np.newaxis, :]\n",
    "ns_vertices = ns_offsets[:, np.newaxis] + ns_ccd_corners[np.newaxis, :]\n",
    "\n",
    "\n",
    "def get_footprint(center):\n",
    "    \"\"\"Return the footprint of the ZTF camera centered at the given position.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    center : astropy.coordinates.SkyCoord\n",
    "        The center of the field or fields: either a single (scalar) sky coord\n",
    "        or an array of sky coordinates of any size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords : astropy.coordinates.SkyCoord\n",
    "        An array of coordinates. If the center is a single sky coordinate, then\n",
    "        the returned array has shape (64, 4), representing the vertices of 64\n",
    "        quadrilaterals. If the center is an array of shape (n, m, ...), then\n",
    "        the returned array has shape (n, m, ..., 64, 4).\n",
    "    \"\"\"\n",
    "    return SkyCoord(\n",
    "        ew_vertices, ns_vertices,\n",
    "        frame=center[..., np.newaxis, np.newaxis].skyoffset_frame()\n",
    "    ).icrs\n",
    "\n",
    "\n",
    "center = SkyCoord(0 * u.deg, 0 * u.deg)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='astro zoom', center='0d 0d', radius=5 * u.deg)\n",
    "for i, verts in enumerate(get_footprint(center)):\n",
    "    rc_center = SkyCoord(*verts.cartesian.xyz.sum(1), representation_type='cartesian')\n",
    "    rc_center.representation_type = 'unitspherical'\n",
    "    ax.add_patch(plt.Polygon(np.column_stack((verts.ra.deg, verts.dec.deg)), edgecolor='k', facecolor='none', transform=ax.get_transform('world')))\n",
    "    ax.text(rc_center.ra.deg, rc_center.dec.deg, str(i), transform=ax.get_transform('world'), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch ZTF field grid\n",
    "\n",
    "Let's download the ZTF field grid from GitHub.\n",
    "\n",
    "(Note that the ZTF field IDs start from 1, and that there are some ranges that are skipped, so the index of a row in this array does not exactly match the field ID. This won't matter for this exercise, but just be aware of it if you are reusing the code in this notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/ZwickyTransientFacility/ztf_information/raw/master/field_grid/ZTF_Fields.txt'\n",
    "filename = download_file(url)\n",
    "field_grid = QTable(np.recfromtxt(filename, comments='%', usecols=range(3), names=['field_id', 'ra', 'dec']))\n",
    "field_grid['coord'] = SkyCoord(field_grid.columns.pop('ra') * u.deg, field_grid.columns.pop('dec') * u.deg)\n",
    "field_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection='astro mollweide')\n",
    "for row in field_grid:\n",
    "    coords = SkyCoord(\n",
    "        [ew_total, -ew_total, -ew_total, ew_total],\n",
    "        [ns_total, ns_total, -ns_total, -ns_total],\n",
    "        frame=row['coord'].skyoffset_frame()\n",
    "    ).icrs\n",
    "    ax.add_patch(plt.Polygon(\n",
    "        np.column_stack((coords.ra.deg, coords.dec.deg)),\n",
    "        alpha=0.5,\n",
    "        facecolor='none',\n",
    "        edgecolor='black',\n",
    "        transform=ax.get_transform('world')\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select fields that are observable\n",
    "\n",
    "We'll filter for fields that are observable at any point during the night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observer site\n",
    "observer = astroplan.Observer.at_site('Palomar')\n",
    "\n",
    "# Find the earliest possible start time of observations.\n",
    "# If it's night time (defined here as the sun being at least 18Â°\n",
    "# below the horizon for astronomical twilight), then the start\n",
    "# time is the time of the event. Otherwise, it's the time of sunset.\n",
    "night_horizon = -18 * u.deg\n",
    "if observer.is_night(event_time, horizon=night_horizon):\n",
    "    start_time = event_time\n",
    "else:\n",
    "    start_time = observer.sun_set_time(\n",
    "        event_time, horizon=night_horizon, which='next')\n",
    "\n",
    "# Find the latest possible end time of observations: the time of sunrise.\n",
    "end_time = observer.sun_rise_time(\n",
    "    start_time, horizon=night_horizon, which='next')\n",
    "\n",
    "\n",
    "min_airmass = 2.5 * u.dimensionless_unscaled\n",
    "airmass_horizon = (90 * u.deg - np.arccos(1 / min_airmass))\n",
    "targets = field_grid['coord']\n",
    "\n",
    "# Find the time that each field rises and sets above an airmass of 2.5.\n",
    "target_start_time = Time(np.where(\n",
    "    observer.target_is_up(start_time, targets, horizon=airmass_horizon),\n",
    "    start_time,\n",
    "    observer.target_rise_time(start_time, targets, which='next', horizon=airmass_horizon)))\n",
    "target_start_time.format = 'iso'\n",
    "\n",
    "# Find the time that each field sets below the airmass limit. If the target\n",
    "# is always up (i.e., it's circumpolar) or if it sets after surnsise,\n",
    "# then set the end time to sunrise.\n",
    "target_end_time = observer.target_set_time(\n",
    "    target_start_time, targets, which='next', horizon=airmass_horizon)\n",
    "target_end_time[\n",
    "    (target_end_time.mask & ~target_start_time.mask) | (target_end_time > end_time)\n",
    "] = end_time\n",
    "target_end_time.format = 'iso'\n",
    "\n",
    "# Select fields that are observable for long enough for at least one exposure\n",
    "# sequence of 1800 seconds.\n",
    "exposure_time = 1800 * u.second\n",
    "field_grid['start_time'] = target_start_time\n",
    "field_grid['end_time'] = target_end_time\n",
    "observable_fields = field_grid[target_end_time - target_start_time >= exposure_time]\n",
    "observable_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection='astro mollweide')\n",
    "for row in observable_fields:\n",
    "    coords = SkyCoord(\n",
    "        [ew_total, -ew_total, -ew_total, ew_total],\n",
    "        [ns_total, ns_total, -ns_total, -ns_total],\n",
    "        frame=row['coord'].skyoffset_frame()\n",
    "    ).icrs\n",
    "    ax.add_patch(plt.Polygon(\n",
    "        np.column_stack((coords.ra.deg, coords.dec.deg)),\n",
    "        alpha=0.5,\n",
    "        facecolor='none',\n",
    "        edgecolor='black',\n",
    "        transform=ax.get_transform('world')\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEALPix representation of ZTF focal plane footprint\n",
    "\n",
    "Now we will model the ZTF focal plane by computing the HEALPix pixel indices contained within the region.\n",
    "\n",
    "Play the value of `nside` to adjust the HEALPix resolution. It must be an integer power of 2.\n",
    "\n",
    "**Exercise 7.** What is the minimum HEALPix resolution to resolve all of the chip gaps?\n",
    "\n",
    "Note that values much larger than `nside=128` will result in problems that take a very long time to solve with HiGHS, and for which you might need to use a professional solver like [CPLEX](https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer), [Gurobi](https://www.gurobi.com), or [FICO Xpress](https://www.fico.com/en/products/fico-xpress-optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill me in: play with the value of nside!\n",
    "hpx = HEALPix(nside=128, frame=ICRS())\n",
    "\n",
    "footprint = np.moveaxis(\n",
    "    get_footprint(SkyCoord(0 * u.deg, 0 * u.deg)).cartesian.xyz.value, 0, -1)\n",
    "footprint_healpix = np.unique(np.concatenate(\n",
    "    [hp.query_polygon(hpx.nside, v, nest=(hpx.order == 'nested')) for v in footprint]))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='astro zoom', center='0d 0d', radius=5 * u.deg)\n",
    "for boundary in hpx.boundaries_skycoord(footprint_healpix, 1):\n",
    "    ax.add_patch(plt.Polygon(np.column_stack((boundary.ra.deg, boundary.dec.deg)), edgecolor='k', facecolor='lightgray', transform=ax.get_transform('world')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected a nice resolution, compute the footprints of every ZTF field as HEALPix indices. Also downsample the sky map to the same resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints = np.moveaxis(get_footprint(observable_fields['coord']).cartesian.xyz.value, 0, -1)\n",
    "footprints_healpix = [\n",
    "    np.unique(np.concatenate([hp.query_polygon(hpx.nside, v) for v in footprint]))\n",
    "    for footprint in tqdm(footprints)]\n",
    "\n",
    "prob = hp.ud_grade(skymap, hpx.nside, power=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn to do the math!\n",
    "\n",
    "### Optimal tiling using max weighted coverage\n",
    "\n",
    "**Exercise 8.** Which 30 fields should ZTF observe in order to follow up this GW event? How much probability is contained in those fields?\n",
    "\n",
    "Hint: Construct a max weighted coverage model of this problem. Express it as a MILP. Write the MILP model in HiGHS and solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = highspy.Highs()\n",
    "\n",
    "field_vars = [model.addBinary() for _ in range(len(footprints))]\n",
    "pixel_vars = [model.addBinary() for _ in range(hpx.npix)]\n",
    "\n",
    "# fill me in...\n",
    "model.addConstr(...)\n",
    "model.maximize(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much probability is contained in the fields that we selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.getObjectiveValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which fields did you pick to observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fields = observable_fields[np.asarray(model.variableValues(field_vars), dtype=bool)]\n",
    "selected_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fields that you selected to observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection='astro mollweide')\n",
    "for row in selected_fields:\n",
    "    coords = SkyCoord(\n",
    "        [ew_total, -ew_total, -ew_total, ew_total],\n",
    "        [ns_total, ns_total, -ns_total, -ns_total],\n",
    "        frame=row['coord'].skyoffset_frame()\n",
    "    ).icrs\n",
    "    ax.add_patch(plt.Polygon(\n",
    "        np.column_stack((coords.ra.deg, coords.dec.deg)),\n",
    "        alpha=0.5,\n",
    "        facecolor='lightgray',\n",
    "        edgecolor='black',\n",
    "        transform=ax.get_transform('world')\n",
    "    ))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal scheduling\n",
    "\n",
    "Now that we have identified which fields to observe, it's time to schedule them: we must decide which fields to observe in what order. For this problem we are going to make use of our **Logical constraints â†”ï¸Ž ILP translation dictionary** from the lecture.\n",
    "\n",
    "We start our model by creating two vectors of decision variables:\n",
    "- The binary vector $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$, where $x_i$ is 1 if we decide to observe field $i$, otherwise 0.\n",
    "- The real vector $\\mathbf{t} = (t_1, t_2, \\dots, t_n)$, where $t_i$ is the start time of the observation of field $i$. Each of these variables will have a lower bound that is the earliest time that the field can be observed, and an upper bound that is the latest time that it can be observed.\n",
    "\n",
    "We want to maximize the total number of fields that we can observe, $\\sum_i x_i$.\n",
    "\n",
    "We need to add some constraints to ensure that the observations do not overlap: we can observe at most one field at a time. If the duration of each exposure is $\\delta$, then in \"pseudocode\" these constraints are:\n",
    "\n",
    "$$\n",
    "\\textnormal{if } x_i = 1, \\textnormal{ then } t_i + \\delta \\leq t_j \\textnormal{ or } t_j + \\delta \\leq t_i \\textnormal{ for all } j < i.\n",
    "$$\n",
    "\n",
    "**Exercise 9**. Using the **Logical constraints â†”ï¸Ž ILP translation dictionary**, express the no-overlap constraints above as a system of linear inequalities suitable for a MILP.\n",
    "\n",
    "Hint: you'll probably use the big-M trick!\n",
    "\n",
    "**Exercise 10**. Complete the code below to model the schedule as an MILP and find the order in which to obseve the ZTF fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = highspy.Highs()\n",
    "\n",
    "# Limit run time; this can take while to solve!\n",
    "# The solver will try to find the best feasible solution within the time limit.\n",
    "model.setOptionValue('time_limit', 60)\n",
    "\n",
    "delta = exposure_time.to_value(u.day)\n",
    "# Fill me in\n",
    "M = ...\n",
    "\n",
    "t = [model.addVariable(\n",
    "        lb=(row['start_time'] - start_time).to_value(u.day),\n",
    "        ub=(row['end_time'] - start_time - exposure_time).to_value(u.day),\n",
    "     ) for row in selected_fields]\n",
    "x = [model.addBinary() for _ in range(len(t))]\n",
    "s = [[model.addBinary() for j in range(i)] for i in range(len(t))]\n",
    "\n",
    "# Fill me in, add constraints...\n",
    "model.addConstr(...)\n",
    "model.maximize(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which fields did you choose to observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_fields = QTable(selected_fields)\n",
    "scheduled_fields['scheduled_start_time'] = Time(model.variableValues(t) + start_time, format='mjd')\n",
    "scheduled_fields['scheduled_start_time'].format = 'iso'\n",
    "scheduled_fields['scheduled_end_time'] = scheduled_fields['scheduled_start_time'] + exposure_time\n",
    "scheduled_fields = scheduled_fields[np.asarray(model.variableValues(x), dtype=bool)]\n",
    "scheduled_fields.sort('scheduled_start_time')\n",
    "scheduled_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scheduled intervals to check that they do not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.hlines(\n",
    "    np.arange(len(scheduled_fields)),\n",
    "    scheduled_fields['scheduled_start_time'].mjd,\n",
    "    scheduled_fields['scheduled_end_time'].mjd)\n",
    "ax.set_yticks(np.arange(len(scheduled_fields)), scheduled_fields['field_id'].astype(str))\n",
    "ax.set_xlabel('Observation time (MJD)')\n",
    "ax.set_ylabel('field ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
